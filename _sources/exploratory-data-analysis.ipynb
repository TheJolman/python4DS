{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f0a171",
   "metadata": {},
   "source": [
    "(exploratory-data-analysis)=\n",
    "# Exploratory Data Analysis\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This chapter will show you how to use visualisation and transformation to explore your data in a systematic way, a task that data scientists call exploratory data analysis, or EDA for short. EDA is an iterative cycle; you:\n",
    "\n",
    "1.  Generate questions about your data.\n",
    "\n",
    "2.  Search for answers by visualising, transforming, and modelling your data.\n",
    "\n",
    "3.  Use what you learn to refine your questions and/or generate new questions.\n",
    "\n",
    "EDA is not a formal process with a strict set of rules and, during the initial phases of EDA, you should feel free to investigate every idea that occurs to you. Some of these ideas will pan out, and some will be dead ends. As your exploration continues, you will home in on a few particularly productive areas that you'll eventually write up and communicate to others. As you explore your data, you should remember that there are some pitfalls: you should always think about how the data were collected, what might be missing, whether there are quality problems, and be really strict about the differences between correlation and causation (this is a huge topic in itself!).\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "For doing EDA, we'll use the **pandas**, **skimpy**, and **pandas-profiling** packages. You are likely to already have **pandas** installed. We'll also need **seaborn** for data visualisation, which can you install with `pip install --pre seaborn`. To install the other two packages, open up a terminal in Visual Studio Code and run `pip install skimpy` and `pip install pandas-profiling`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a55374",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib_inline.backend_inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use(\"https://github.com/aeturrell/python4DS/raw/main/plot_style.txt\")\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ddb863",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "> \"There are no routine statistical questions, only questionable statistical routines.\" --- Sir David Cox\n",
    "> \"Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong question, which can always be made precise.\" --- John Tukey\n",
    "\n",
    "Your goal during EDA is to develop an understanding of your data. The easiest way to do this is to use questions as tools to guide your investigation. When you ask a question, the question focuses your attention on a specific part of your dataset and helps you decide which graphs, models, or transformations to make.\n",
    "\n",
    "EDA is fundamentally a creative process. And like most creative processes, the key to asking *quality* questions is to generate a large *quantity* of questions. It is difficult to ask revealing questions at the start of your analysis because you do not know what insights are contained in your dataset. On the other hand, each new question that you ask will expose you to a new aspect of your data and increase your chance of making a discovery. You can quickly drill down into the most interesting parts of your data---and develop a set of thought-provoking questions---if you follow up each question with a new question based on what you find.\n",
    "\n",
    "There is no rule about which questions you should ask to guide your research. However, two types of questions will always be useful for making discoveries within your data. You can loosely word these questions as:\n",
    "\n",
    "1.  What type of variation occurs within my variables?\n",
    "\n",
    "2.  What type of covariation occurs between my variables?\n",
    "\n",
    "The rest of this chapter will look at these two questions. We'll explain what variation and covariation are, and We'll show you several ways to answer each question. To make the discussion easier, let's define some terms:\n",
    "\n",
    "-   A **variable** is a quantity, quality, or property that you can measure.\n",
    "\n",
    "-   A **value** is the state of a variable when you measure it. The value of a variable may change from measurement to measurement.\n",
    "\n",
    "-   An **observation** is a set of measurements made under similar conditions (you usually make all of the measurements in an observation at the same time and on the same object). An observation will contain several values, each associated with a different variable. We'll sometimes refer to an observation as a data point.\n",
    "\n",
    "-   **Tabular data** is a set of values, each associated with a variable and an observation. Tabular data is *tidy* if each value is placed in its own \"cell\", each variable in its own column, and each observation in its own row.\n",
    "\n",
    "So far, all of the data that you've seen has been tidy. In real-life, most data isn't tidy, so we'll come back to how to clean untidy data later in the book."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adeff41",
   "metadata": {},
   "source": [
    "## Variation\n",
    "\n",
    "**Variation** is the tendency of the values of a variable to change from measurement to measurement. You can see variation easily in real life; if you measure any continuous variable twice, you will get two different results. This is true even if you measure quantities that are constant, like the speed of light. Each of your measurements include a small amount of error that varies from measurement to measurement. Variables can also vary if you measure across different subjects (e.g. the eye colours of different people) or different times (e.g. the energy levels of an electron at different moments).\n",
    "\n",
    "Every variable has its own pattern of variation, which can reveal interesting information about how that variable varies between measurements on the same observation as well as across observations. The best way to understand that pattern is to visualise the distribution of the variable's values.\n",
    "\n",
    "### Visualising distributions\n",
    "\n",
    "How you visualize the distribution of a variable will depend on whether the variable is categorical or continuous. A variable is **categorical** if it can only take one of a small set of values. In data analysis in Python, categorical variables are usually saved as the 'category' type in **pandas** data frames. To examine the distribution of a categorical variable, you can use a bar chart. First let's load up **seaborn** for visusalisation and load up the diamonds dataset in **pandas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e3b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn.objects as so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f4de95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "diamonds = pd.read_csv(\n",
    "    \"https://github.com/mwaskom/seaborn-data/raw/master/diamonds.csv\"\n",
    ")\n",
    "diamonds[\"cut\"] = diamonds[\"cut\"].astype(\"category\")\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86240820",
   "metadata": {},
   "source": [
    "Now we can visualise the data using a bar chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eca1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(so.Plot(diamonds, \"cut\").add(so.Bar(), so.Hist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb60dea5",
   "metadata": {},
   "source": [
    "The height of the bars displays how many observations occurred with each x value. You can compute these values directly with **pandas** too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934db5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds[\"cut\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953fd423",
   "metadata": {},
   "source": [
    "A variable is **continuous** if it can take any of an infinite set of ordered values. Numbers and date-times are two examples of continuous variables. To examine the distribution of a continuous variable, you can use a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c4cc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(so.Plot(diamonds, \"carat\").add(so.Bar(), so.Hist(binwidth=0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc08384d",
   "metadata": {},
   "source": [
    "You can also compute this directly using **pandas** using `pd.cut` to assign a category (an interval) to each row and then `value_counts()` to count the number of rows in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d87bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(diamonds[\"carat\"], bins=11).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e9b67d",
   "metadata": {},
   "source": [
    "A histogram divides the x-axis into equally spaced bins and then uses the height of a bar to display the number of observations that fall in each bin. You can set the number of intervals in a histogram plot with the `binwidth=` keyword argument, which is measured in the units of the `x` variable. You should always explore a variety of binwidths when working with histograms, as different binwidths can reveal different patterns.\n",
    "\n",
    "For example, here is how the graph above looks when we zoom into just the diamonds with a size of less than three carats and choose a smaller binwidth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a142d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "(so.Plot(diamonds.query(\"carat < 3\"), \"carat\").add(so.Bar(), so.Hist(binwidth=0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8f6dbe",
   "metadata": {},
   "source": [
    "Now that you can visualise variation, what should you look for in your plots? And what type of follow-up questions should you ask? Below is a list of the most useful types of information that you will find in your graphs, along with some follow-up questions for each type of information. The key to asking good follow-up questions will be to rely on your curiosity (What do you want to learn more about?) as well as your skepticism (How could this be misleading?)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc70e63",
   "metadata": {},
   "source": [
    "### Typical Values\n",
    "\n",
    "In both bar charts and histograms, tall bars show the common values of a variable, and shorter bars show less-common values.\n",
    "Places that do not have bars reveal values that were not seen in your data.\n",
    "To turn this information into useful questions, look for anything unexpected:\n",
    "\n",
    "-   Which values are the most common?\n",
    "    Why?\n",
    "\n",
    "-   Which values are rare?\n",
    "    Why?\n",
    "    Does that match your expectations?\n",
    "\n",
    "-   Can you see any unusual patterns?\n",
    "    What might explain them?\n",
    "\n",
    "As an example, the histogram below suggests several interesting questions:\n",
    "\n",
    "-   Why are there more diamonds at whole carats and common fractions of carats?\n",
    "\n",
    "-   Why are there more diamonds slightly to the right of each peak than there are slightly to the left of each peak?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b131f1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "(so.Plot(diamonds.query(\"carat < 3\"), \"carat\").add(so.Bar(), so.Hist(binwidth=0.01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b18aa",
   "metadata": {},
   "source": [
    "Clusters of similar values suggest that subgroups exist in your data.\n",
    "To understand the subgroups, ask:\n",
    "\n",
    "-   How are the observations within each cluster similar to each other?\n",
    "\n",
    "-   How are the observations in separate clusters different from each other?\n",
    "\n",
    "-   How can you explain or describe the clusters?\n",
    "\n",
    "-   Why might the appearance of clusters be misleading?\n",
    "\n",
    "Many of the questions above will prompt you to explore a relationship *between* variables, for example, to see if the values of one variable can explain the behavior of another variable. We'll get to that shortly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29461679",
   "metadata": {},
   "source": [
    "### Unusual Values\n",
    "\n",
    "Outliers are observations that are unusual; data points that don't seem to fit the pattern.\n",
    "Sometimes outliers are data entry errors; other times outliers suggest important new science.\n",
    "When you have a lot of data, outliers are sometimes difficult to see in a histogram.\n",
    "For example, take the distribution of the `y` variable from the diamonds dataset.\n",
    "The only evidence of outliers is the unusually wide limits on the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274112a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(so.Plot(diamonds, \"y\").add(so.Bar(), so.Hist(binwidth=0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4702d7fc",
   "metadata": {},
   "source": [
    "There are so many observations in the common bins that the rare bins are very short, making it very difficult to see them (although maybe if you stare intently at 0 you'll spot something). To make it easy to see the unusual values, we need to zoom to small values of the y-axis with a special value of the scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06924e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue raised\n",
    "# (\n",
    "#     so.Plot(diamonds, x=\"y\")\n",
    "#     .add(so.Bar(), so.Hist(binwidth=0.5))\n",
    "#     .scale(y=so.Continuous(trans=None).tick(at=[0, 50]))\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bba593",
   "metadata": {},
   "source": [
    "The `y` variable measures one of the three dimensions of these diamonds, in mm.\n",
    "We know that diamonds can't have a width of 0mm, so these values must be incorrect.\n",
    "We might also suspect that measurements of 32mm and 59mm are implausible: those diamonds are over an inch long, but don't cost hundreds of thousands of dollars!\n",
    "\n",
    "It's good practice to repeat your analysis with and without the outliers. If they have minimal effect on the results, and you can't figure out why they're there, it's reasonable to omit them, and move on.\n",
    "\n",
    "However, if they have a substantial effect on your results, you shouldn't drop them without justification.\n",
    "You'll need to figure out what caused them (e.g. a data entry error) and disclose that you removed them in your write-up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0e2e67",
   "metadata": {},
   "source": [
    "### Replacing Unusual Values\n",
    "\n",
    "If you’ve encountered unusual values in your dataset, and simply want to move on to the rest of your analysis (not your only response—you can also consider filling in the missing data), you have two options:\n",
    "\n",
    "1. Drop the entire row with the strange values. You can do this by just working with a subset of the data, eg`diamonds.query('3 <= y <= 20')`. This option isn't generally recommended though as just because one measurement is invalid, it doesn’t mean all the measurements are. Additionally, if you have low quality data, by time that you’ve applied this approach to every variable you might find that you don’t have any data left!\n",
    "2. Replacing the unusual values with empty cells (ie remove those values entirely). The easiest way to do this is to use `assign()` to replace the variable with a modified copy. You can use the `np.where()` function to replace unusual values with `np.nan`, the **numpy** missing value operator:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d186896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "diamonds[\"y\"] = diamonds[\"y\"].apply(lambda y: np.where(20 > y > 3, y, np.nan))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e73854",
   "metadata": {},
   "source": [
    "`np.where()` typically has three arguments. The first argument condition should be a column of booleans. If `True`, then the next argument will be used; if `False`, the third. So we get the pattern `np.where(<CONDITION>, <VALUE IF CONDITION TRUE>, <VALUE IF CONDITION FALSE>)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14158b48",
   "metadata": {},
   "source": [
    "## **pandas** built-in tools for EDA\n",
    "\n",
    "**pandas** has some great options for built-in EDA; in fact we've already seen one of them, `df.info()` which, as well as reporting datatypes and memory usage, also tells us how many observations in each column are 'truthy' rather than 'falsy', ie how many have non-null values.\n",
    "\n",
    "### Exploratory tables and descriptive statistics\n",
    "\n",
    "A small step beyond `.info()` to get tables is to use `.describe()` which, if you have mixed datatypes that include floats, will report some basic summary statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13079065",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db57dbb7",
   "metadata": {},
   "source": [
    "Although helpful, that sure is hard to read! We can improve this by using the `round()` method too:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4144440",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_table = diamonds.describe().round(1)\n",
    "sum_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8063b8f5",
   "metadata": {},
   "source": [
    "Published summary statistics tables often list one variable per row, and if your dataframe has many variables, `describe()` can quickly get too wide to read easily. You can transpose it using the `T` property (or the `transpose()` method):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f8772",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_table = sum_table.T\n",
    "sum_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67104d3",
   "metadata": {},
   "source": [
    "Of course, the stats provided in this pre-built table are not very customised. So what do we do to get the table that we actually want? Well, the answer is to draw on the contents of the previous data chapters, particularly the introduction to data analysis. Groupbys, merges, aggregations: use all of them to produce the EDA table that you want.\n",
    "\n",
    "If you're exploring data, you might also want to be able to read everything clearly and see any deviations from what you'd expect quickly. **pandas** has some built-in functionality that styles dataframes to help you. These styles persist when you export the dataframe to, say, Excel, too.\n",
    "\n",
    "Here's an example that highlights some ways of styling dataframes, making use of several features such as: unstacking into a wider format (`unstack`), changing the units (`lambda` function; note that `1e3` is shorthand for `1000` on computers), fill NaNs with unobtrusive strings (`.fillna('-')`), removing numbers after the decimal place (`.style.format(precision=0)`), and adding a caption (`.style.set_caption`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afcacbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    diamonds.groupby([\"cut\", \"color\"])\n",
    "    .mean()[\"price\"]\n",
    "    .unstack()\n",
    "    .apply(lambda x: x / 1e3)\n",
    "    .fillna(\"-\")\n",
    "    .style.format(precision=2)\n",
    "    .set_caption(\"Sale price (thousands)\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e0fc1",
   "metadata": {},
   "source": [
    "Although a neater one than we've seen, this is still a drab table of numbers. The eye is not immediately drawn to it!\n",
    "\n",
    "To remedy that, let's take a look at another styling technique: the use of colour. Let's say we wanted to make a table that showed a cross-tabulation between cut and color; that is the counts of objects appearing in both of these fields according to the categories.\n",
    "\n",
    "To perform a cross-tabulation, we'll use the built-in `pd.crosstab` but we'll ask that the values that appear in the table (counts) be lit up with a heatmap using `style.background_gradient` too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e65189",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(diamonds[\"color\"], diamonds[\"cut\"]).style.background_gradient(cmap=\"plasma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c6aa71",
   "metadata": {},
   "source": [
    "By default, `background_gradient` highlights each number relative to the others in its column; you can highlight by row using `axis=1` or relative to all table values using `axis=0`. And of course `plasma` is just one of [many available colormaps](https://matplotlib.org/stable/tutorials/colors/colormaps.html)!\n",
    "\n",
    "```{admonition} Exercise\n",
    "Do a new cross-tabulation using a different colourmap.\n",
    "```\n",
    "\n",
    "Here are a couple of other styling tips for dataframes.\n",
    "\n",
    "First, use bars to show ordering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0162ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pd.crosstab(diamonds[\"color\"], diamonds[\"cut\"])\n",
    "    .style.format(precision=0)\n",
    "    .bar(color=\"#d65f5f\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36d4795",
   "metadata": {},
   "source": [
    "Use `.hightlight_max`, and similar commands, to show important entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(diamonds[\"color\"], diamonds[\"cut\"]).style.highlight_max().format(\"{:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63075da4",
   "metadata": {},
   "source": [
    "You can find a full set of styling commands [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html#Styling)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b6d225",
   "metadata": {},
   "source": [
    "### Exploratory Plotting with **pandas**\n",
    "\n",
    "**pandas** has some built-in plotting options to help you look at data quickly. These can be accessed via `.plot.*` or `.plot()`, depending on the context. Let's make a quick `.plot()` using a dataset on taxis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b479d5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis = pd.read_csv(\"https://github.com/mwaskom/seaborn-data/raw/master/taxis.csv\")\n",
    "# turn the pickup time column into a datetime\n",
    "# taxis[\"pickup\"] = pd.to_datetime(taxis[\"pickup\"])\n",
    "# set some other columns types\n",
    "taxis = taxis.astype(\n",
    "    {\n",
    "        \"dropoff\": \"datetime64\",\n",
    "        \"pickup\": \"datetime64\",\n",
    "        \"color\": \"category\",\n",
    "        \"payment\": \"category\",\n",
    "        \"pickup_zone\": \"string\",\n",
    "        \"dropoff_zone\": \"string\",\n",
    "        \"pickup_borough\": \"category\",\n",
    "        \"dropoff_borough\": \"category\",\n",
    "    }\n",
    ")\n",
    "taxis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee971c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2015b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    taxis.set_index(\"pickup\")\n",
    "    .groupby(pd.Grouper(freq=\"D\"))[\"total\"]\n",
    "    .mean()\n",
    "    .plot(\n",
    "        title=\"Mean taxi fares\",\n",
    "        xlabel=\"\",\n",
    "        ylabel=\"Fare (USD)\",\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c0f990",
   "metadata": {},
   "source": [
    "Again, if you can get the data in the right shape, you can plot it. The same function works with multiple lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e86185",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    taxis.set_index(\"pickup\")\n",
    "    .groupby(pd.Grouper(freq=\"D\"))[[\"fare\", \"tip\", \"tolls\"]]\n",
    "    .mean()\n",
    "    .plot(\n",
    "        style=[\"-\", \":\", \"-.\"],\n",
    "        title=\"Components of taxi fares\",\n",
    "        xlabel=\"\",\n",
    "        ylabel=\"USD\",\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc227b81",
   "metadata": {},
   "source": [
    "Now let's see some of the other quick `.plot.*` options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4278ac",
   "metadata": {},
   "source": [
    "A bar chart (use `barh` for horizontal orientation; `rot` sets rotation of labels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ceca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis.value_counts(\"payment\").sort_index().plot.bar(title=\"Counts\", rot=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6f1cc2",
   "metadata": {},
   "source": [
    "This next one, uses `.plot.hist` to create a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc5817",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis[\"tip\"].plot.hist(bins=30, title=\"Tip\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f15bfa7",
   "metadata": {},
   "source": [
    "Boxplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b735d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "(taxis[[\"fare\", \"tolls\", \"tip\"]].plot.box());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67017bef",
   "metadata": {},
   "source": [
    "Scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66adada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis.plot.scatter(x=\"fare\", y=\"tip\", alpha=0.7, ylim=(0, None));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9766d2c4",
   "metadata": {},
   "source": [
    "## Other tools for EDA\n",
    "\n",
    "Between **pandas** and visualisation packages, you have a lot of what you need for EDA. But there are some tools just dedicated to making EDA easier that it's worth knowing about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813ec70a",
   "metadata": {},
   "source": [
    "### **skimpy** for summary statistics\n",
    "\n",
    "The **skimpy** package is a light weight tool that provides summary statistics about variables in data frames in the console (rather than in a big HTML report, which is what the other EDA packages in the rest of this chapter too). Sometimes running `.summary()` on a data frame isn't enough, and **skimpy** fills this gap. It also comes with the `clean_columns` function for cleaning column names that we saw in an earlier chapter. To install **skimpy**, run `pip install skimpy` in the terminal.\n",
    "\n",
    "Let's see **skimpy** in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32796b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimpy import skim\n",
    "\n",
    "skim(taxis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1fc099",
   "metadata": {},
   "source": [
    "### The **pandas-profiling** package\n",
    "\n",
    "The EDA we did using the built-in **pandas** functions was a bit limited and user-input heavy. The [**pandas-profiling**](https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/) library aims to automate the legwork of EDA for you. It generates 'profile' reports from a pandas DataFrame. For each column, many statistics are computed and then relayed in an interactive HTML report. To install it, run `pip install pandas-profiling` in the terminal.\n",
    "\n",
    "Let's generate a report on our dataset. If you are using a large dataset, you may wish to employ the`minimal=True` setting that cuts out a lot of computationally expensive extras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39739f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "\n",
    "profile = ProfileReport(taxis, minimal=True, title=\"Profiling Report: Taxis Dataset\")\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2494069",
   "metadata": {},
   "source": [
    "This is a full on report about everything in our dataset! We can see, for instance, that we have 14 variables and what kind each of them are.\n",
    "\n",
    "The alerts page shows where **pandas-profiling** really shines. It flags *potential* issues with the data that should be taken into account in any subsequent analysis. For example, although not relevant here, the report will say if there are very unbalanced classes in a low cardinality categorical variable.\n",
    "\n",
    "Another good package for automated EDA is [dataprep](https://dataprep.ai/)."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d7534ecd9fbc7d385378f8400cf4d6cb9c6175408a574f1c99c5269f08771cc"
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "md:myst",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
